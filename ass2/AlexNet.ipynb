{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torchvision\n",
    "from torchvision import transforms,datasets\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32,padding=1),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914,0.4882,0.4465),(0.2023,0.1994,0.2010)),\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32,padding=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914,0.4882,0.4465),(0.2023,0.1994,0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.CIFAR10(root='./cs231n/datasets',train=True,download=False,transform=train_transform)\n",
    "train_loader = Data.DataLoader(train_data,batch_size=128, shuffle=True)\n",
    "\n",
    "test_data = datasets.CIFAR10(root='./cs231n/datasets',train=False,download=False,transform=test_transform)\n",
    "test_loader = Data.DataLoader(test_data,batch_size=128,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#因为用的是Cifar10数据集所以将网络的规模设置的比较小\n",
    "class alexnet_bianzhong(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(alexnet_bianzhong,self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            nn.Conv2d(3,96,5,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(96,256,5,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(256,384,3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384,384,3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384,256,3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256*4*4,200),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(200,200),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(200,10),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.feature(x)\n",
    "        x = x.view(x.size()[0],-1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    }
   ],
   "source": [
    "print(256*16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process(model,optimizer,epoches):\n",
    "    model.train()\n",
    "    for e in range(epoches):\n",
    "        sum_loss = 0.0\n",
    "        for i, t in enumerate(train_loader):\n",
    "            x, y = t\n",
    "            x, y = Variable(x).cuda(),Variable(y).cuda()\n",
    "#             print(x.shape)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores,y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()\n",
    "            if i % 20 == 0:\n",
    "                print('Iteration:%d batch:%d %.03f '%(e,i,sum_loss))\n",
    "                sum_loss = 0.0\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_process(model):\n",
    "    model.eval()\n",
    "    num, correct= 0, 0\n",
    "    for i,(x,y) in enumerate(test_loader):\n",
    "        x, y = Variable(x).cuda(), Variable(y).cuda()\n",
    "        scores = model(x)\n",
    "        _, pre = scores.max(1)\n",
    "        num += scores.size()[0]\n",
    "        correct += (pre==y).sum()\n",
    "        acc = float(correct)/num\n",
    "        print('%d %.03f'%(i,acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =alexnet_bianzhong().cuda()\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.SGD(model.parameters(),lr=learning_rate,momentum=0.9,weight_decay=5e-4)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:0 batch:0 230.655 \n",
      "Iteration:0 batch:20 4605.149 \n",
      "Iteration:0 batch:40 4610.941 \n",
      "Iteration:0 batch:60 4608.252 \n",
      "Iteration:0 batch:80 4603.929 \n",
      "Iteration:0 batch:100 4605.952 \n",
      "Iteration:0 batch:120 4606.651 \n",
      "Iteration:0 batch:140 4603.148 \n",
      "Iteration:0 batch:160 4601.970 \n",
      "Iteration:0 batch:180 4601.101 \n",
      "Iteration:0 batch:200 4601.234 \n",
      "Iteration:0 batch:220 4599.508 \n",
      "Iteration:0 batch:240 4602.357 \n",
      "Iteration:0 batch:260 4596.796 \n",
      "Iteration:0 batch:280 4598.846 \n",
      "Iteration:0 batch:300 4593.542 \n",
      "Iteration:0 batch:320 4592.732 \n",
      "Iteration:0 batch:340 4588.928 \n",
      "Iteration:0 batch:360 4589.317 \n",
      "Iteration:0 batch:380 4585.502 \n",
      "Iteration:1 batch:0 229.279 \n",
      "Iteration:1 batch:20 4579.183 \n",
      "Iteration:1 batch:40 4564.944 \n",
      "Iteration:1 batch:60 4561.756 \n",
      "Iteration:1 batch:80 4546.027 \n",
      "Iteration:1 batch:100 4532.317 \n",
      "Iteration:1 batch:120 4495.621 \n",
      "Iteration:1 batch:140 4471.215 \n",
      "Iteration:1 batch:160 4450.271 \n",
      "Iteration:1 batch:180 4376.242 \n",
      "Iteration:1 batch:200 4345.869 \n",
      "Iteration:1 batch:220 4299.130 \n",
      "Iteration:1 batch:240 4233.439 \n",
      "Iteration:1 batch:260 4187.153 \n",
      "Iteration:1 batch:280 4182.408 \n",
      "Iteration:1 batch:300 4125.642 \n",
      "Iteration:1 batch:320 4112.696 \n",
      "Iteration:1 batch:340 4070.704 \n",
      "Iteration:1 batch:360 4043.190 \n",
      "Iteration:1 batch:380 3968.691 \n",
      "Iteration:2 batch:0 204.641 \n",
      "Iteration:2 batch:20 4009.198 \n",
      "Iteration:2 batch:40 3982.123 \n",
      "Iteration:2 batch:60 3912.793 \n",
      "Iteration:2 batch:80 3962.634 \n",
      "Iteration:2 batch:100 3937.724 \n",
      "Iteration:2 batch:120 3934.894 \n",
      "Iteration:2 batch:140 3868.690 \n",
      "Iteration:2 batch:160 3902.699 \n",
      "Iteration:2 batch:180 3848.194 \n",
      "Iteration:2 batch:200 3809.451 \n",
      "Iteration:2 batch:220 3751.415 \n",
      "Iteration:2 batch:240 3806.771 \n",
      "Iteration:2 batch:260 3780.581 \n",
      "Iteration:2 batch:280 3786.696 \n",
      "Iteration:2 batch:300 3741.387 \n",
      "Iteration:2 batch:320 3716.169 \n",
      "Iteration:2 batch:340 3700.654 \n",
      "Iteration:2 batch:360 3668.373 \n",
      "Iteration:2 batch:380 3723.816 \n",
      "Iteration:3 batch:0 180.015 \n",
      "Iteration:3 batch:20 3653.165 \n",
      "Iteration:3 batch:40 3658.311 \n",
      "Iteration:3 batch:60 3619.903 \n",
      "Iteration:3 batch:80 3542.755 \n",
      "Iteration:3 batch:100 3569.124 \n",
      "Iteration:3 batch:120 3540.463 \n",
      "Iteration:3 batch:140 3594.897 \n",
      "Iteration:3 batch:160 3553.824 \n",
      "Iteration:3 batch:180 3524.490 \n",
      "Iteration:3 batch:200 3483.370 \n",
      "Iteration:3 batch:220 3452.340 \n",
      "Iteration:3 batch:240 3497.869 \n",
      "Iteration:3 batch:260 3514.220 \n",
      "Iteration:3 batch:280 3471.687 \n",
      "Iteration:3 batch:300 3511.085 \n",
      "Iteration:3 batch:320 3397.237 \n",
      "Iteration:3 batch:340 3482.790 \n",
      "Iteration:3 batch:360 3381.326 \n",
      "Iteration:3 batch:380 3399.172 \n",
      "Iteration:4 batch:0 162.739 \n",
      "Iteration:4 batch:20 3444.604 \n",
      "Iteration:4 batch:40 3359.755 \n",
      "Iteration:4 batch:60 3324.445 \n",
      "Iteration:4 batch:80 3334.971 \n",
      "Iteration:4 batch:100 3422.808 \n",
      "Iteration:4 batch:120 3388.063 \n",
      "Iteration:4 batch:140 3293.744 \n",
      "Iteration:4 batch:160 3315.983 \n",
      "Iteration:4 batch:180 3334.397 \n",
      "Iteration:4 batch:200 3280.935 \n",
      "Iteration:4 batch:220 3268.109 \n",
      "Iteration:4 batch:240 3261.578 \n",
      "Iteration:4 batch:260 3258.418 \n",
      "Iteration:4 batch:280 3272.984 \n",
      "Iteration:4 batch:300 3226.340 \n",
      "Iteration:4 batch:320 3265.971 \n",
      "Iteration:4 batch:340 3292.958 \n",
      "Iteration:4 batch:360 3254.648 \n",
      "Iteration:4 batch:380 3227.401 \n",
      "Iteration:5 batch:0 156.131 \n",
      "Iteration:5 batch:20 3198.883 \n",
      "Iteration:5 batch:40 3283.797 \n",
      "Iteration:5 batch:60 3193.966 \n",
      "Iteration:5 batch:80 3161.785 \n",
      "Iteration:5 batch:100 3183.176 \n",
      "Iteration:5 batch:120 3231.314 \n",
      "Iteration:5 batch:140 3168.926 \n",
      "Iteration:5 batch:160 3134.547 \n",
      "Iteration:5 batch:180 3145.859 \n",
      "Iteration:5 batch:200 3095.899 \n",
      "Iteration:5 batch:220 3172.156 \n",
      "Iteration:5 batch:240 3205.501 \n",
      "Iteration:5 batch:260 3142.248 \n",
      "Iteration:5 batch:280 3146.534 \n",
      "Iteration:5 batch:300 3132.735 \n",
      "Iteration:5 batch:320 3107.352 \n",
      "Iteration:5 batch:340 3110.818 \n",
      "Iteration:5 batch:360 2997.535 \n",
      "Iteration:5 batch:380 3028.760 \n",
      "Iteration:6 batch:0 165.375 \n",
      "Iteration:6 batch:20 3009.856 \n",
      "Iteration:6 batch:40 3045.467 \n",
      "Iteration:6 batch:60 3036.631 \n",
      "Iteration:6 batch:80 3028.859 \n",
      "Iteration:6 batch:100 3046.846 \n",
      "Iteration:6 batch:120 2990.902 \n",
      "Iteration:6 batch:140 3023.915 \n",
      "Iteration:6 batch:160 3021.400 \n",
      "Iteration:6 batch:180 2977.986 \n",
      "Iteration:6 batch:200 2999.996 \n",
      "Iteration:6 batch:220 2928.476 \n",
      "Iteration:6 batch:240 3012.482 \n",
      "Iteration:6 batch:260 2975.916 \n",
      "Iteration:6 batch:280 3043.017 \n",
      "Iteration:6 batch:300 2949.215 \n",
      "Iteration:6 batch:320 3055.940 \n",
      "Iteration:6 batch:340 2953.615 \n",
      "Iteration:6 batch:360 2910.961 \n",
      "Iteration:6 batch:380 2991.084 \n",
      "Iteration:7 batch:0 139.246 \n",
      "Iteration:7 batch:20 2932.354 \n",
      "Iteration:7 batch:40 2888.784 \n",
      "Iteration:7 batch:60 2960.955 \n",
      "Iteration:7 batch:80 2968.793 \n",
      "Iteration:7 batch:100 2898.438 \n",
      "Iteration:7 batch:120 2914.673 \n",
      "Iteration:7 batch:140 2839.982 \n",
      "Iteration:7 batch:160 2862.695 \n",
      "Iteration:7 batch:180 2923.992 \n",
      "Iteration:7 batch:200 2918.427 \n",
      "Iteration:7 batch:220 2848.840 \n",
      "Iteration:7 batch:240 2787.198 \n",
      "Iteration:7 batch:260 2843.725 \n",
      "Iteration:7 batch:280 2780.818 \n",
      "Iteration:7 batch:300 2822.298 \n",
      "Iteration:7 batch:320 2901.356 \n",
      "Iteration:7 batch:340 2948.963 \n",
      "Iteration:7 batch:360 2771.029 \n",
      "Iteration:7 batch:380 2800.645 \n",
      "Iteration:8 batch:0 134.277 \n",
      "Iteration:8 batch:20 2810.648 \n",
      "Iteration:8 batch:40 2881.781 \n",
      "Iteration:8 batch:60 2837.349 \n",
      "Iteration:8 batch:80 2814.175 \n",
      "Iteration:8 batch:100 2789.823 \n",
      "Iteration:8 batch:120 2793.120 \n",
      "Iteration:8 batch:140 2756.358 \n",
      "Iteration:8 batch:160 2780.264 \n",
      "Iteration:8 batch:180 2734.644 \n",
      "Iteration:8 batch:200 2692.369 \n",
      "Iteration:8 batch:220 2765.028 \n",
      "Iteration:8 batch:240 2674.831 \n",
      "Iteration:8 batch:260 2797.872 \n",
      "Iteration:8 batch:280 2755.492 \n",
      "Iteration:8 batch:300 2692.269 \n",
      "Iteration:8 batch:320 2673.509 \n",
      "Iteration:8 batch:340 2813.126 \n",
      "Iteration:8 batch:360 2725.761 \n",
      "Iteration:8 batch:380 2701.127 \n",
      "Iteration:9 batch:0 133.621 \n",
      "Iteration:9 batch:20 2784.405 \n",
      "Iteration:9 batch:40 2754.255 \n",
      "Iteration:9 batch:60 2705.850 \n",
      "Iteration:9 batch:80 2708.381 \n",
      "Iteration:9 batch:100 2564.702 \n",
      "Iteration:9 batch:120 2606.025 \n",
      "Iteration:9 batch:140 2632.611 \n",
      "Iteration:9 batch:160 2611.972 \n",
      "Iteration:9 batch:180 2663.645 \n",
      "Iteration:9 batch:200 2611.474 \n",
      "Iteration:9 batch:220 2634.257 \n",
      "Iteration:9 batch:240 2625.524 \n",
      "Iteration:9 batch:260 2667.503 \n",
      "Iteration:9 batch:280 2646.021 \n",
      "Iteration:9 batch:300 2647.672 \n",
      "Iteration:9 batch:320 2629.110 \n",
      "Iteration:9 batch:340 2652.713 \n",
      "Iteration:9 batch:360 2643.841 \n",
      "Iteration:9 batch:380 2558.451 \n"
     ]
    }
   ],
   "source": [
    "train_process(model,optimizer,epoches=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 55.469\n",
      "1 51.953\n",
      "2 53.125\n",
      "3 53.711\n",
      "4 54.219\n",
      "5 53.516\n",
      "6 53.237\n",
      "7 54.688\n",
      "8 54.514\n",
      "9 54.922\n",
      "10 54.759\n",
      "11 55.339\n",
      "12 55.228\n",
      "13 55.190\n",
      "14 55.365\n",
      "15 55.420\n",
      "16 55.469\n",
      "17 55.382\n",
      "18 55.304\n",
      "19 55.039\n",
      "20 54.836\n",
      "21 54.545\n",
      "22 54.620\n",
      "23 54.850\n",
      "24 55.094\n",
      "25 55.048\n",
      "26 54.832\n",
      "27 54.799\n",
      "28 54.688\n",
      "29 54.714\n",
      "30 54.738\n",
      "31 54.565\n",
      "32 54.593\n",
      "33 54.802\n",
      "34 54.665\n",
      "35 54.536\n",
      "36 54.540\n",
      "37 54.523\n",
      "38 54.567\n",
      "39 54.395\n",
      "40 54.325\n",
      "41 54.222\n",
      "42 54.161\n",
      "43 54.208\n",
      "44 54.358\n",
      "45 54.246\n",
      "46 54.205\n",
      "47 54.102\n",
      "48 54.050\n",
      "49 54.031\n",
      "50 53.983\n",
      "51 53.816\n",
      "52 53.729\n",
      "53 53.791\n",
      "54 53.594\n",
      "55 53.683\n",
      "56 53.618\n",
      "57 53.704\n",
      "58 53.774\n",
      "59 53.659\n",
      "60 53.676\n",
      "61 53.616\n",
      "62 53.646\n",
      "63 53.699\n",
      "64 53.558\n",
      "65 53.551\n",
      "66 53.556\n",
      "67 53.493\n",
      "68 53.499\n",
      "69 53.504\n",
      "70 53.499\n",
      "71 53.570\n",
      "72 53.671\n",
      "73 53.653\n",
      "74 53.781\n",
      "75 53.834\n",
      "76 53.764\n",
      "77 53.716\n",
      "78 53.700\n"
     ]
    }
   ],
   "source": [
    "test_process(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:face]",
   "language": "python",
   "name": "conda-env-face-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
