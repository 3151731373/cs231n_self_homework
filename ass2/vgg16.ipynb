{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32,padding=1),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010)),\n",
    "])\n",
    "transforms_test = transforms.Compose([\n",
    "    transforms.RandomCrop(32,padding=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.CIFAR10(root='./cs231n/datasets',train=True,download=False,transform=transform_train)\n",
    "test_data = datasets.CIFAR10(root='./cs231n/datasets',train=False,download=False,transform=transforms_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch_size = 64\n",
    "train_loader = Data.DataLoader(train_data,batch_size=Batch_size,shuffle=True)\n",
    "test_loader = Data.DataLoader(test_data,batch_size=Batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = [64,64,'M',128,128,'M',256,256,256,'M',512,512,512,'M',512,512,512,'M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_layers(cfg):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(2)]\n",
    "        else:\n",
    "            layers +=[nn.Conv2d(in_channels,v,3,padding=1),nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vgg16(nn.Module):\n",
    "    def __init__(self,feature,data_num,num_classes):\n",
    "        super(vgg16,self).__init__()\n",
    "        self.feature = feature\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512,256),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256,128),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128,num_classes),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.feature(x)\n",
    "        x = x.view(x.size()[0],-1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ./cs231n/datasets\n",
      "    Split: Train\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = make_layers(cfg)\n",
    "data_num = 64\n",
    "model = vgg16(feature,data_num,10).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = optim.SGD(model.parameters(),lr=learning_rate,momentum=0.9, weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process(model,optimizer,epoches = 1):\n",
    "    model.train()\n",
    "    for e in range(epoches):\n",
    "        for i,data in enumerate(train_loader):\n",
    "            \n",
    "            x, y = data\n",
    "            x, y = Variable(x).cuda(), Variable(y).cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            scores = model(x)\n",
    "#             print(scores.shape,y.shape)\n",
    "            loss = F.cross_entropy(scores,y)\n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if(i%10==0):\n",
    "                print(\"iteration [%d/%d] loss:%.03f\"%(e,epoches,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [0/10] loss:0.290\n",
      "iteration [0/10] loss:0.323\n",
      "iteration [0/10] loss:0.468\n",
      "iteration [0/10] loss:0.368\n",
      "iteration [0/10] loss:0.578\n",
      "iteration [0/10] loss:0.502\n",
      "iteration [0/10] loss:0.448\n",
      "iteration [0/10] loss:0.345\n",
      "iteration [0/10] loss:0.496\n",
      "iteration [0/10] loss:0.239\n",
      "iteration [0/10] loss:0.386\n",
      "iteration [0/10] loss:0.385\n",
      "iteration [0/10] loss:0.384\n",
      "iteration [0/10] loss:0.206\n",
      "iteration [0/10] loss:0.301\n",
      "iteration [0/10] loss:0.273\n",
      "iteration [0/10] loss:0.281\n",
      "iteration [0/10] loss:0.228\n",
      "iteration [0/10] loss:0.198\n",
      "iteration [0/10] loss:0.146\n",
      "iteration [0/10] loss:0.295\n",
      "iteration [0/10] loss:0.321\n",
      "iteration [0/10] loss:0.239\n",
      "iteration [0/10] loss:0.304\n",
      "iteration [0/10] loss:0.375\n",
      "iteration [0/10] loss:0.152\n",
      "iteration [0/10] loss:0.423\n",
      "iteration [0/10] loss:0.183\n",
      "iteration [0/10] loss:0.595\n",
      "iteration [0/10] loss:0.464\n",
      "iteration [0/10] loss:0.218\n",
      "iteration [0/10] loss:0.358\n",
      "iteration [0/10] loss:0.260\n",
      "iteration [0/10] loss:0.386\n",
      "iteration [0/10] loss:0.343\n",
      "iteration [0/10] loss:0.264\n",
      "iteration [0/10] loss:0.257\n",
      "iteration [0/10] loss:0.334\n",
      "iteration [0/10] loss:0.303\n",
      "iteration [0/10] loss:0.301\n",
      "iteration [0/10] loss:0.379\n",
      "iteration [0/10] loss:0.259\n",
      "iteration [0/10] loss:0.623\n",
      "iteration [0/10] loss:0.318\n",
      "iteration [0/10] loss:0.481\n",
      "iteration [0/10] loss:0.492\n",
      "iteration [0/10] loss:0.355\n",
      "iteration [0/10] loss:0.504\n",
      "iteration [0/10] loss:0.225\n",
      "iteration [0/10] loss:0.413\n",
      "iteration [0/10] loss:0.347\n",
      "iteration [0/10] loss:0.375\n",
      "iteration [0/10] loss:0.354\n",
      "iteration [0/10] loss:0.431\n",
      "iteration [0/10] loss:0.627\n",
      "iteration [0/10] loss:0.620\n",
      "iteration [0/10] loss:0.376\n",
      "iteration [0/10] loss:0.223\n",
      "iteration [0/10] loss:0.546\n",
      "iteration [0/10] loss:0.309\n",
      "iteration [0/10] loss:0.367\n",
      "iteration [0/10] loss:0.272\n",
      "iteration [0/10] loss:0.237\n",
      "iteration [0/10] loss:0.363\n",
      "iteration [0/10] loss:0.444\n",
      "iteration [0/10] loss:0.340\n",
      "iteration [0/10] loss:0.229\n",
      "iteration [0/10] loss:0.314\n",
      "iteration [0/10] loss:0.183\n",
      "iteration [0/10] loss:0.398\n",
      "iteration [0/10] loss:0.563\n",
      "iteration [0/10] loss:0.502\n",
      "iteration [0/10] loss:0.345\n",
      "iteration [0/10] loss:0.336\n",
      "iteration [0/10] loss:0.509\n",
      "iteration [0/10] loss:0.412\n",
      "iteration [0/10] loss:0.263\n",
      "iteration [0/10] loss:0.402\n",
      "iteration [0/10] loss:0.484\n",
      "iteration [1/10] loss:0.217\n",
      "iteration [1/10] loss:0.314\n",
      "iteration [1/10] loss:0.328\n",
      "iteration [1/10] loss:0.201\n",
      "iteration [1/10] loss:0.422\n",
      "iteration [1/10] loss:0.407\n",
      "iteration [1/10] loss:0.172\n",
      "iteration [1/10] loss:0.265\n",
      "iteration [1/10] loss:0.175\n",
      "iteration [1/10] loss:0.295\n",
      "iteration [1/10] loss:0.165\n",
      "iteration [1/10] loss:0.251\n",
      "iteration [1/10] loss:0.323\n",
      "iteration [1/10] loss:0.262\n",
      "iteration [1/10] loss:0.247\n",
      "iteration [1/10] loss:0.265\n",
      "iteration [1/10] loss:0.307\n",
      "iteration [1/10] loss:0.301\n",
      "iteration [1/10] loss:0.183\n",
      "iteration [1/10] loss:0.519\n",
      "iteration [1/10] loss:0.508\n",
      "iteration [1/10] loss:0.236\n",
      "iteration [1/10] loss:0.283\n",
      "iteration [1/10] loss:0.256\n",
      "iteration [1/10] loss:0.524\n",
      "iteration [1/10] loss:0.141\n",
      "iteration [1/10] loss:0.524\n",
      "iteration [1/10] loss:0.312\n",
      "iteration [1/10] loss:0.279\n",
      "iteration [1/10] loss:0.382\n",
      "iteration [1/10] loss:0.362\n",
      "iteration [1/10] loss:0.217\n",
      "iteration [1/10] loss:0.245\n",
      "iteration [1/10] loss:0.196\n",
      "iteration [1/10] loss:0.280\n",
      "iteration [1/10] loss:0.360\n",
      "iteration [1/10] loss:0.311\n",
      "iteration [1/10] loss:0.284\n",
      "iteration [1/10] loss:0.230\n",
      "iteration [1/10] loss:0.193\n",
      "iteration [1/10] loss:0.371\n",
      "iteration [1/10] loss:0.404\n",
      "iteration [1/10] loss:0.342\n",
      "iteration [1/10] loss:0.350\n",
      "iteration [1/10] loss:0.358\n",
      "iteration [1/10] loss:0.265\n",
      "iteration [1/10] loss:0.252\n",
      "iteration [1/10] loss:0.388\n",
      "iteration [1/10] loss:0.312\n",
      "iteration [1/10] loss:0.434\n",
      "iteration [1/10] loss:0.388\n",
      "iteration [1/10] loss:0.285\n",
      "iteration [1/10] loss:0.260\n",
      "iteration [1/10] loss:0.418\n",
      "iteration [1/10] loss:0.323\n",
      "iteration [1/10] loss:0.224\n",
      "iteration [1/10] loss:0.339\n",
      "iteration [1/10] loss:0.224\n",
      "iteration [1/10] loss:0.319\n",
      "iteration [1/10] loss:0.369\n",
      "iteration [1/10] loss:0.305\n",
      "iteration [1/10] loss:0.324\n",
      "iteration [1/10] loss:0.307\n",
      "iteration [1/10] loss:0.316\n",
      "iteration [1/10] loss:0.296\n",
      "iteration [1/10] loss:0.323\n",
      "iteration [1/10] loss:0.152\n",
      "iteration [1/10] loss:0.371\n",
      "iteration [1/10] loss:0.326\n",
      "iteration [1/10] loss:0.182\n",
      "iteration [1/10] loss:0.389\n",
      "iteration [1/10] loss:0.461\n",
      "iteration [1/10] loss:0.183\n",
      "iteration [1/10] loss:0.410\n",
      "iteration [1/10] loss:0.234\n",
      "iteration [1/10] loss:0.342\n",
      "iteration [1/10] loss:0.254\n",
      "iteration [1/10] loss:0.329\n",
      "iteration [1/10] loss:0.175\n",
      "iteration [2/10] loss:0.235\n",
      "iteration [2/10] loss:0.190\n",
      "iteration [2/10] loss:0.162\n",
      "iteration [2/10] loss:0.197\n",
      "iteration [2/10] loss:0.240\n",
      "iteration [2/10] loss:0.523\n",
      "iteration [2/10] loss:0.203\n",
      "iteration [2/10] loss:0.339\n",
      "iteration [2/10] loss:0.253\n",
      "iteration [2/10] loss:0.457\n",
      "iteration [2/10] loss:0.091\n",
      "iteration [2/10] loss:0.477\n",
      "iteration [2/10] loss:0.324\n",
      "iteration [2/10] loss:0.329\n",
      "iteration [2/10] loss:0.330\n",
      "iteration [2/10] loss:0.436\n",
      "iteration [2/10] loss:0.323\n",
      "iteration [2/10] loss:0.210\n",
      "iteration [2/10] loss:0.556\n",
      "iteration [2/10] loss:0.312\n",
      "iteration [2/10] loss:0.230\n",
      "iteration [2/10] loss:0.340\n",
      "iteration [2/10] loss:0.365\n",
      "iteration [2/10] loss:0.283\n",
      "iteration [2/10] loss:0.569\n",
      "iteration [2/10] loss:0.254\n",
      "iteration [2/10] loss:0.225\n",
      "iteration [2/10] loss:0.319\n",
      "iteration [2/10] loss:0.379\n",
      "iteration [2/10] loss:0.426\n",
      "iteration [2/10] loss:0.239\n",
      "iteration [2/10] loss:0.201\n",
      "iteration [2/10] loss:0.432\n",
      "iteration [2/10] loss:0.197\n",
      "iteration [2/10] loss:0.254\n",
      "iteration [2/10] loss:0.290\n",
      "iteration [2/10] loss:0.262\n",
      "iteration [2/10] loss:0.233\n",
      "iteration [2/10] loss:0.347\n",
      "iteration [2/10] loss:0.344\n",
      "iteration [2/10] loss:0.325\n",
      "iteration [2/10] loss:0.294\n",
      "iteration [2/10] loss:0.335\n",
      "iteration [2/10] loss:0.312\n",
      "iteration [2/10] loss:0.209\n",
      "iteration [2/10] loss:0.258\n",
      "iteration [2/10] loss:0.142\n",
      "iteration [2/10] loss:0.385\n",
      "iteration [2/10] loss:0.322\n",
      "iteration [2/10] loss:0.467\n",
      "iteration [2/10] loss:0.418\n",
      "iteration [2/10] loss:0.269\n",
      "iteration [2/10] loss:0.362\n",
      "iteration [2/10] loss:0.151\n",
      "iteration [2/10] loss:0.256\n",
      "iteration [2/10] loss:0.391\n",
      "iteration [2/10] loss:0.348\n",
      "iteration [2/10] loss:0.163\n",
      "iteration [2/10] loss:0.200\n",
      "iteration [2/10] loss:0.328\n",
      "iteration [2/10] loss:0.206\n",
      "iteration [2/10] loss:0.294\n",
      "iteration [2/10] loss:0.219\n",
      "iteration [2/10] loss:0.335\n",
      "iteration [2/10] loss:0.259\n",
      "iteration [2/10] loss:0.355\n",
      "iteration [2/10] loss:0.269\n",
      "iteration [2/10] loss:0.242\n",
      "iteration [2/10] loss:0.204\n",
      "iteration [2/10] loss:0.261\n",
      "iteration [2/10] loss:0.347\n",
      "iteration [2/10] loss:0.409\n",
      "iteration [2/10] loss:0.354\n",
      "iteration [2/10] loss:0.257\n",
      "iteration [2/10] loss:0.360\n",
      "iteration [2/10] loss:0.456\n",
      "iteration [2/10] loss:0.226\n",
      "iteration [2/10] loss:0.277\n",
      "iteration [2/10] loss:0.597\n",
      "iteration [3/10] loss:0.304\n",
      "iteration [3/10] loss:0.234\n",
      "iteration [3/10] loss:0.332\n",
      "iteration [3/10] loss:0.195\n",
      "iteration [3/10] loss:0.189\n",
      "iteration [3/10] loss:0.244\n",
      "iteration [3/10] loss:0.226\n",
      "iteration [3/10] loss:0.266\n",
      "iteration [3/10] loss:0.568\n",
      "iteration [3/10] loss:0.334\n",
      "iteration [3/10] loss:0.194\n",
      "iteration [3/10] loss:0.214\n",
      "iteration [3/10] loss:0.357\n",
      "iteration [3/10] loss:0.297\n",
      "iteration [3/10] loss:0.140\n",
      "iteration [3/10] loss:0.360\n",
      "iteration [3/10] loss:0.170\n",
      "iteration [3/10] loss:0.199\n",
      "iteration [3/10] loss:0.313\n",
      "iteration [3/10] loss:0.273\n",
      "iteration [3/10] loss:0.220\n",
      "iteration [3/10] loss:0.386\n",
      "iteration [3/10] loss:0.517\n",
      "iteration [3/10] loss:0.397\n",
      "iteration [3/10] loss:0.315\n",
      "iteration [3/10] loss:0.450\n",
      "iteration [3/10] loss:0.283\n",
      "iteration [3/10] loss:0.458\n",
      "iteration [3/10] loss:0.273\n",
      "iteration [3/10] loss:0.349\n",
      "iteration [3/10] loss:0.150\n",
      "iteration [3/10] loss:0.374\n",
      "iteration [3/10] loss:0.568\n",
      "iteration [3/10] loss:0.344\n",
      "iteration [3/10] loss:0.444\n",
      "iteration [3/10] loss:0.222\n",
      "iteration [3/10] loss:0.195\n",
      "iteration [3/10] loss:0.437\n",
      "iteration [3/10] loss:0.295\n",
      "iteration [3/10] loss:0.140\n",
      "iteration [3/10] loss:0.259\n",
      "iteration [3/10] loss:0.351\n",
      "iteration [3/10] loss:0.181\n",
      "iteration [3/10] loss:0.201\n",
      "iteration [3/10] loss:0.226\n",
      "iteration [3/10] loss:0.116\n",
      "iteration [3/10] loss:0.184\n",
      "iteration [3/10] loss:0.423\n",
      "iteration [3/10] loss:0.265\n",
      "iteration [3/10] loss:0.296\n",
      "iteration [3/10] loss:0.169\n",
      "iteration [3/10] loss:0.319\n",
      "iteration [3/10] loss:0.280\n",
      "iteration [3/10] loss:0.287\n",
      "iteration [3/10] loss:0.210\n",
      "iteration [3/10] loss:0.223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [3/10] loss:0.230\n",
      "iteration [3/10] loss:0.362\n",
      "iteration [3/10] loss:0.356\n",
      "iteration [3/10] loss:0.363\n",
      "iteration [3/10] loss:0.249\n",
      "iteration [3/10] loss:0.218\n",
      "iteration [3/10] loss:0.333\n",
      "iteration [3/10] loss:0.338\n",
      "iteration [3/10] loss:0.330\n",
      "iteration [3/10] loss:0.351\n",
      "iteration [3/10] loss:0.172\n",
      "iteration [3/10] loss:0.311\n",
      "iteration [3/10] loss:0.241\n",
      "iteration [3/10] loss:0.167\n",
      "iteration [3/10] loss:0.152\n",
      "iteration [3/10] loss:0.209\n",
      "iteration [3/10] loss:0.250\n",
      "iteration [3/10] loss:0.303\n",
      "iteration [3/10] loss:0.507\n",
      "iteration [3/10] loss:0.347\n",
      "iteration [3/10] loss:0.454\n",
      "iteration [3/10] loss:0.311\n",
      "iteration [3/10] loss:0.173\n",
      "iteration [4/10] loss:0.195\n",
      "iteration [4/10] loss:0.262\n",
      "iteration [4/10] loss:0.303\n",
      "iteration [4/10] loss:0.205\n",
      "iteration [4/10] loss:0.212\n",
      "iteration [4/10] loss:0.304\n",
      "iteration [4/10] loss:0.187\n",
      "iteration [4/10] loss:0.282\n",
      "iteration [4/10] loss:0.329\n",
      "iteration [4/10] loss:0.254\n",
      "iteration [4/10] loss:0.407\n",
      "iteration [4/10] loss:0.286\n",
      "iteration [4/10] loss:0.288\n",
      "iteration [4/10] loss:0.227\n",
      "iteration [4/10] loss:0.227\n",
      "iteration [4/10] loss:0.305\n",
      "iteration [4/10] loss:0.128\n",
      "iteration [4/10] loss:0.145\n",
      "iteration [4/10] loss:0.343\n",
      "iteration [4/10] loss:0.292\n",
      "iteration [4/10] loss:0.180\n",
      "iteration [4/10] loss:0.338\n",
      "iteration [4/10] loss:0.335\n",
      "iteration [4/10] loss:0.255\n",
      "iteration [4/10] loss:0.283\n",
      "iteration [4/10] loss:0.223\n",
      "iteration [4/10] loss:0.548\n",
      "iteration [4/10] loss:0.198\n",
      "iteration [4/10] loss:0.298\n",
      "iteration [4/10] loss:0.422\n",
      "iteration [4/10] loss:0.133\n",
      "iteration [4/10] loss:0.410\n",
      "iteration [4/10] loss:0.149\n",
      "iteration [4/10] loss:0.247\n",
      "iteration [4/10] loss:0.246\n",
      "iteration [4/10] loss:0.288\n",
      "iteration [4/10] loss:0.210\n",
      "iteration [4/10] loss:0.183\n",
      "iteration [4/10] loss:0.355\n",
      "iteration [4/10] loss:0.300\n",
      "iteration [4/10] loss:0.263\n",
      "iteration [4/10] loss:0.328\n",
      "iteration [4/10] loss:0.458\n",
      "iteration [4/10] loss:0.166\n",
      "iteration [4/10] loss:0.289\n",
      "iteration [4/10] loss:0.212\n",
      "iteration [4/10] loss:0.114\n",
      "iteration [4/10] loss:0.463\n",
      "iteration [4/10] loss:0.219\n",
      "iteration [4/10] loss:0.370\n",
      "iteration [4/10] loss:0.415\n",
      "iteration [4/10] loss:0.235\n",
      "iteration [4/10] loss:0.241\n",
      "iteration [4/10] loss:0.129\n",
      "iteration [4/10] loss:0.206\n",
      "iteration [4/10] loss:0.300\n",
      "iteration [4/10] loss:0.317\n",
      "iteration [4/10] loss:0.271\n",
      "iteration [4/10] loss:0.146\n",
      "iteration [4/10] loss:0.162\n",
      "iteration [4/10] loss:0.206\n",
      "iteration [4/10] loss:0.121\n",
      "iteration [4/10] loss:0.357\n",
      "iteration [4/10] loss:0.384\n",
      "iteration [4/10] loss:0.286\n",
      "iteration [4/10] loss:0.217\n",
      "iteration [4/10] loss:0.452\n",
      "iteration [4/10] loss:0.262\n",
      "iteration [4/10] loss:0.120\n",
      "iteration [4/10] loss:0.405\n",
      "iteration [4/10] loss:0.258\n",
      "iteration [4/10] loss:0.282\n",
      "iteration [4/10] loss:0.313\n",
      "iteration [4/10] loss:0.189\n",
      "iteration [4/10] loss:0.416\n",
      "iteration [4/10] loss:0.233\n",
      "iteration [4/10] loss:0.219\n",
      "iteration [4/10] loss:0.258\n",
      "iteration [4/10] loss:0.267\n",
      "iteration [5/10] loss:0.400\n",
      "iteration [5/10] loss:0.373\n",
      "iteration [5/10] loss:0.137\n",
      "iteration [5/10] loss:0.162\n",
      "iteration [5/10] loss:0.199\n",
      "iteration [5/10] loss:0.253\n",
      "iteration [5/10] loss:0.184\n",
      "iteration [5/10] loss:0.400\n",
      "iteration [5/10] loss:0.491\n",
      "iteration [5/10] loss:0.244\n",
      "iteration [5/10] loss:0.269\n",
      "iteration [5/10] loss:0.195\n",
      "iteration [5/10] loss:0.275\n",
      "iteration [5/10] loss:0.185\n",
      "iteration [5/10] loss:0.179\n",
      "iteration [5/10] loss:0.255\n",
      "iteration [5/10] loss:0.137\n",
      "iteration [5/10] loss:0.056\n",
      "iteration [5/10] loss:0.123\n",
      "iteration [5/10] loss:0.065\n",
      "iteration [5/10] loss:0.156\n",
      "iteration [5/10] loss:0.303\n",
      "iteration [5/10] loss:0.183\n",
      "iteration [5/10] loss:0.131\n",
      "iteration [5/10] loss:0.330\n",
      "iteration [5/10] loss:0.076\n",
      "iteration [5/10] loss:0.270\n",
      "iteration [5/10] loss:0.151\n",
      "iteration [5/10] loss:0.382\n",
      "iteration [5/10] loss:0.364\n",
      "iteration [5/10] loss:0.392\n",
      "iteration [5/10] loss:0.101\n",
      "iteration [5/10] loss:0.254\n",
      "iteration [5/10] loss:0.435\n",
      "iteration [5/10] loss:0.270\n",
      "iteration [5/10] loss:0.327\n",
      "iteration [5/10] loss:0.253\n",
      "iteration [5/10] loss:0.112\n",
      "iteration [5/10] loss:0.215\n",
      "iteration [5/10] loss:0.143\n",
      "iteration [5/10] loss:0.159\n",
      "iteration [5/10] loss:0.166\n",
      "iteration [5/10] loss:0.097\n",
      "iteration [5/10] loss:0.209\n",
      "iteration [5/10] loss:0.267\n",
      "iteration [5/10] loss:0.277\n",
      "iteration [5/10] loss:0.235\n",
      "iteration [5/10] loss:0.160\n",
      "iteration [5/10] loss:0.117\n",
      "iteration [5/10] loss:0.336\n",
      "iteration [5/10] loss:0.125\n",
      "iteration [5/10] loss:0.150\n",
      "iteration [5/10] loss:0.290\n",
      "iteration [5/10] loss:0.348\n",
      "iteration [5/10] loss:0.147\n",
      "iteration [5/10] loss:0.240\n",
      "iteration [5/10] loss:0.148\n",
      "iteration [5/10] loss:0.256\n",
      "iteration [5/10] loss:0.274\n",
      "iteration [5/10] loss:0.240\n",
      "iteration [5/10] loss:0.196\n",
      "iteration [5/10] loss:0.235\n",
      "iteration [5/10] loss:0.412\n",
      "iteration [5/10] loss:0.295\n",
      "iteration [5/10] loss:0.124\n",
      "iteration [5/10] loss:0.218\n",
      "iteration [5/10] loss:0.156\n",
      "iteration [5/10] loss:0.223\n",
      "iteration [5/10] loss:0.076\n",
      "iteration [5/10] loss:0.509\n",
      "iteration [5/10] loss:0.363\n",
      "iteration [5/10] loss:0.292\n",
      "iteration [5/10] loss:0.368\n",
      "iteration [5/10] loss:0.230\n",
      "iteration [5/10] loss:0.278\n",
      "iteration [5/10] loss:0.242\n",
      "iteration [5/10] loss:0.205\n",
      "iteration [5/10] loss:0.177\n",
      "iteration [5/10] loss:0.176\n",
      "iteration [6/10] loss:0.281\n",
      "iteration [6/10] loss:0.221\n",
      "iteration [6/10] loss:0.244\n",
      "iteration [6/10] loss:0.156\n",
      "iteration [6/10] loss:0.128\n",
      "iteration [6/10] loss:0.270\n",
      "iteration [6/10] loss:0.226\n",
      "iteration [6/10] loss:0.178\n",
      "iteration [6/10] loss:0.159\n",
      "iteration [6/10] loss:0.243\n",
      "iteration [6/10] loss:0.228\n",
      "iteration [6/10] loss:0.201\n",
      "iteration [6/10] loss:0.155\n",
      "iteration [6/10] loss:0.167\n",
      "iteration [6/10] loss:0.215\n",
      "iteration [6/10] loss:0.315\n",
      "iteration [6/10] loss:0.299\n",
      "iteration [6/10] loss:0.136\n",
      "iteration [6/10] loss:0.237\n",
      "iteration [6/10] loss:0.360\n",
      "iteration [6/10] loss:0.353\n",
      "iteration [6/10] loss:0.150\n",
      "iteration [6/10] loss:0.266\n",
      "iteration [6/10] loss:0.152\n",
      "iteration [6/10] loss:0.277\n",
      "iteration [6/10] loss:0.141\n",
      "iteration [6/10] loss:0.176\n",
      "iteration [6/10] loss:0.176\n",
      "iteration [6/10] loss:0.091\n",
      "iteration [6/10] loss:0.090\n",
      "iteration [6/10] loss:0.397\n",
      "iteration [6/10] loss:0.053\n",
      "iteration [6/10] loss:0.579\n",
      "iteration [6/10] loss:0.147\n",
      "iteration [6/10] loss:0.267\n",
      "iteration [6/10] loss:0.131\n",
      "iteration [6/10] loss:0.387\n",
      "iteration [6/10] loss:0.088\n",
      "iteration [6/10] loss:0.242\n",
      "iteration [6/10] loss:0.374\n",
      "iteration [6/10] loss:0.228\n",
      "iteration [6/10] loss:0.315\n",
      "iteration [6/10] loss:0.196\n",
      "iteration [6/10] loss:0.134\n",
      "iteration [6/10] loss:0.310\n",
      "iteration [6/10] loss:0.177\n",
      "iteration [6/10] loss:0.190\n",
      "iteration [6/10] loss:0.250\n",
      "iteration [6/10] loss:0.319\n",
      "iteration [6/10] loss:0.172\n",
      "iteration [6/10] loss:0.216\n",
      "iteration [6/10] loss:0.234\n",
      "iteration [6/10] loss:0.238\n",
      "iteration [6/10] loss:0.201\n",
      "iteration [6/10] loss:0.381\n",
      "iteration [6/10] loss:0.203\n",
      "iteration [6/10] loss:0.162\n",
      "iteration [6/10] loss:0.310\n",
      "iteration [6/10] loss:0.129\n",
      "iteration [6/10] loss:0.218\n",
      "iteration [6/10] loss:0.190\n",
      "iteration [6/10] loss:0.246\n",
      "iteration [6/10] loss:0.221\n",
      "iteration [6/10] loss:0.549\n",
      "iteration [6/10] loss:0.184\n",
      "iteration [6/10] loss:0.123\n",
      "iteration [6/10] loss:0.231\n",
      "iteration [6/10] loss:0.161\n",
      "iteration [6/10] loss:0.255\n",
      "iteration [6/10] loss:0.171\n",
      "iteration [6/10] loss:0.206\n",
      "iteration [6/10] loss:0.151\n",
      "iteration [6/10] loss:0.259\n",
      "iteration [6/10] loss:0.430\n",
      "iteration [6/10] loss:0.160\n",
      "iteration [6/10] loss:0.193\n",
      "iteration [6/10] loss:0.258\n",
      "iteration [6/10] loss:0.306\n",
      "iteration [6/10] loss:0.317\n",
      "iteration [7/10] loss:0.230\n",
      "iteration [7/10] loss:0.089\n",
      "iteration [7/10] loss:0.143\n",
      "iteration [7/10] loss:0.129\n",
      "iteration [7/10] loss:0.293\n",
      "iteration [7/10] loss:0.083\n",
      "iteration [7/10] loss:0.132\n",
      "iteration [7/10] loss:0.126\n",
      "iteration [7/10] loss:0.130\n",
      "iteration [7/10] loss:0.069\n",
      "iteration [7/10] loss:0.259\n",
      "iteration [7/10] loss:0.175\n",
      "iteration [7/10] loss:0.320\n",
      "iteration [7/10] loss:0.395\n",
      "iteration [7/10] loss:0.166\n",
      "iteration [7/10] loss:0.233\n",
      "iteration [7/10] loss:0.447\n",
      "iteration [7/10] loss:0.408\n",
      "iteration [7/10] loss:0.239\n",
      "iteration [7/10] loss:0.123\n",
      "iteration [7/10] loss:0.241\n",
      "iteration [7/10] loss:0.156\n",
      "iteration [7/10] loss:0.181\n",
      "iteration [7/10] loss:0.163\n",
      "iteration [7/10] loss:0.107\n",
      "iteration [7/10] loss:0.363\n",
      "iteration [7/10] loss:0.176\n",
      "iteration [7/10] loss:0.167\n",
      "iteration [7/10] loss:0.159\n",
      "iteration [7/10] loss:0.183\n",
      "iteration [7/10] loss:0.277\n",
      "iteration [7/10] loss:0.226\n",
      "iteration [7/10] loss:0.167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [7/10] loss:0.249\n",
      "iteration [7/10] loss:0.198\n",
      "iteration [7/10] loss:0.191\n",
      "iteration [7/10] loss:0.090\n",
      "iteration [7/10] loss:0.164\n",
      "iteration [7/10] loss:0.118\n",
      "iteration [7/10] loss:0.215\n",
      "iteration [7/10] loss:0.445\n",
      "iteration [7/10] loss:0.285\n",
      "iteration [7/10] loss:0.225\n",
      "iteration [7/10] loss:0.120\n",
      "iteration [7/10] loss:0.371\n",
      "iteration [7/10] loss:0.222\n",
      "iteration [7/10] loss:0.175\n",
      "iteration [7/10] loss:0.273\n",
      "iteration [7/10] loss:0.135\n",
      "iteration [7/10] loss:0.232\n",
      "iteration [7/10] loss:0.147\n",
      "iteration [7/10] loss:0.165\n",
      "iteration [7/10] loss:0.278\n",
      "iteration [7/10] loss:0.261\n",
      "iteration [7/10] loss:0.287\n",
      "iteration [7/10] loss:0.314\n",
      "iteration [7/10] loss:0.294\n",
      "iteration [7/10] loss:0.100\n",
      "iteration [7/10] loss:0.306\n",
      "iteration [7/10] loss:0.125\n",
      "iteration [7/10] loss:0.211\n",
      "iteration [7/10] loss:0.159\n",
      "iteration [7/10] loss:0.171\n",
      "iteration [7/10] loss:0.255\n",
      "iteration [7/10] loss:0.219\n",
      "iteration [7/10] loss:0.188\n",
      "iteration [7/10] loss:0.158\n",
      "iteration [7/10] loss:0.230\n",
      "iteration [7/10] loss:0.352\n",
      "iteration [7/10] loss:0.134\n",
      "iteration [7/10] loss:0.324\n",
      "iteration [7/10] loss:0.214\n",
      "iteration [7/10] loss:0.427\n",
      "iteration [7/10] loss:0.068\n",
      "iteration [7/10] loss:0.162\n",
      "iteration [7/10] loss:0.289\n",
      "iteration [7/10] loss:0.403\n",
      "iteration [7/10] loss:0.338\n",
      "iteration [7/10] loss:0.118\n",
      "iteration [8/10] loss:0.084\n",
      "iteration [8/10] loss:0.348\n",
      "iteration [8/10] loss:0.275\n",
      "iteration [8/10] loss:0.196\n",
      "iteration [8/10] loss:0.078\n",
      "iteration [8/10] loss:0.212\n",
      "iteration [8/10] loss:0.252\n",
      "iteration [8/10] loss:0.128\n",
      "iteration [8/10] loss:0.150\n",
      "iteration [8/10] loss:0.209\n",
      "iteration [8/10] loss:0.131\n",
      "iteration [8/10] loss:0.305\n",
      "iteration [8/10] loss:0.148\n",
      "iteration [8/10] loss:0.145\n",
      "iteration [8/10] loss:0.173\n",
      "iteration [8/10] loss:0.400\n",
      "iteration [8/10] loss:0.071\n",
      "iteration [8/10] loss:0.200\n",
      "iteration [8/10] loss:0.220\n",
      "iteration [8/10] loss:0.182\n",
      "iteration [8/10] loss:0.145\n",
      "iteration [8/10] loss:0.079\n",
      "iteration [8/10] loss:0.179\n",
      "iteration [8/10] loss:0.124\n",
      "iteration [8/10] loss:0.234\n",
      "iteration [8/10] loss:0.211\n",
      "iteration [8/10] loss:0.170\n",
      "iteration [8/10] loss:0.114\n",
      "iteration [8/10] loss:0.352\n",
      "iteration [8/10] loss:0.146\n",
      "iteration [8/10] loss:0.263\n",
      "iteration [8/10] loss:0.083\n",
      "iteration [8/10] loss:0.232\n",
      "iteration [8/10] loss:0.161\n",
      "iteration [8/10] loss:0.293\n",
      "iteration [8/10] loss:0.230\n",
      "iteration [8/10] loss:0.224\n",
      "iteration [8/10] loss:0.091\n",
      "iteration [8/10] loss:0.268\n",
      "iteration [8/10] loss:0.219\n",
      "iteration [8/10] loss:0.213\n",
      "iteration [8/10] loss:0.235\n",
      "iteration [8/10] loss:0.224\n",
      "iteration [8/10] loss:0.152\n",
      "iteration [8/10] loss:0.166\n",
      "iteration [8/10] loss:0.304\n",
      "iteration [8/10] loss:0.052\n",
      "iteration [8/10] loss:0.429\n",
      "iteration [8/10] loss:0.111\n",
      "iteration [8/10] loss:0.183\n",
      "iteration [8/10] loss:0.187\n",
      "iteration [8/10] loss:0.115\n",
      "iteration [8/10] loss:0.285\n",
      "iteration [8/10] loss:0.109\n",
      "iteration [8/10] loss:0.216\n",
      "iteration [8/10] loss:0.104\n",
      "iteration [8/10] loss:0.175\n",
      "iteration [8/10] loss:0.301\n",
      "iteration [8/10] loss:0.148\n",
      "iteration [8/10] loss:0.211\n",
      "iteration [8/10] loss:0.157\n",
      "iteration [8/10] loss:0.211\n",
      "iteration [8/10] loss:0.047\n",
      "iteration [8/10] loss:0.300\n",
      "iteration [8/10] loss:0.208\n",
      "iteration [8/10] loss:0.166\n",
      "iteration [8/10] loss:0.164\n",
      "iteration [8/10] loss:0.260\n",
      "iteration [8/10] loss:0.158\n",
      "iteration [8/10] loss:0.224\n",
      "iteration [8/10] loss:0.157\n",
      "iteration [8/10] loss:0.165\n",
      "iteration [8/10] loss:0.151\n",
      "iteration [8/10] loss:0.114\n",
      "iteration [8/10] loss:0.069\n",
      "iteration [8/10] loss:0.234\n",
      "iteration [8/10] loss:0.160\n",
      "iteration [8/10] loss:0.122\n",
      "iteration [8/10] loss:0.126\n",
      "iteration [9/10] loss:0.170\n",
      "iteration [9/10] loss:0.180\n",
      "iteration [9/10] loss:0.080\n",
      "iteration [9/10] loss:0.138\n",
      "iteration [9/10] loss:0.147\n",
      "iteration [9/10] loss:0.153\n",
      "iteration [9/10] loss:0.209\n",
      "iteration [9/10] loss:0.144\n",
      "iteration [9/10] loss:0.165\n",
      "iteration [9/10] loss:0.243\n",
      "iteration [9/10] loss:0.225\n",
      "iteration [9/10] loss:0.043\n",
      "iteration [9/10] loss:0.151\n",
      "iteration [9/10] loss:0.198\n",
      "iteration [9/10] loss:0.200\n",
      "iteration [9/10] loss:0.222\n",
      "iteration [9/10] loss:0.207\n",
      "iteration [9/10] loss:0.180\n",
      "iteration [9/10] loss:0.077\n",
      "iteration [9/10] loss:0.083\n",
      "iteration [9/10] loss:0.082\n",
      "iteration [9/10] loss:0.137\n",
      "iteration [9/10] loss:0.095\n",
      "iteration [9/10] loss:0.087\n",
      "iteration [9/10] loss:0.139\n",
      "iteration [9/10] loss:0.082\n",
      "iteration [9/10] loss:0.294\n",
      "iteration [9/10] loss:0.182\n",
      "iteration [9/10] loss:0.128\n",
      "iteration [9/10] loss:0.597\n",
      "iteration [9/10] loss:0.195\n",
      "iteration [9/10] loss:0.347\n",
      "iteration [9/10] loss:0.152\n",
      "iteration [9/10] loss:0.327\n",
      "iteration [9/10] loss:0.152\n",
      "iteration [9/10] loss:0.245\n",
      "iteration [9/10] loss:0.121\n",
      "iteration [9/10] loss:0.259\n",
      "iteration [9/10] loss:0.264\n",
      "iteration [9/10] loss:0.208\n",
      "iteration [9/10] loss:0.271\n",
      "iteration [9/10] loss:0.139\n",
      "iteration [9/10] loss:0.089\n",
      "iteration [9/10] loss:0.124\n",
      "iteration [9/10] loss:0.263\n",
      "iteration [9/10] loss:0.282\n",
      "iteration [9/10] loss:0.335\n",
      "iteration [9/10] loss:0.175\n",
      "iteration [9/10] loss:0.192\n",
      "iteration [9/10] loss:0.200\n",
      "iteration [9/10] loss:0.089\n",
      "iteration [9/10] loss:0.160\n",
      "iteration [9/10] loss:0.217\n",
      "iteration [9/10] loss:0.188\n",
      "iteration [9/10] loss:0.164\n",
      "iteration [9/10] loss:0.218\n",
      "iteration [9/10] loss:0.158\n",
      "iteration [9/10] loss:0.220\n",
      "iteration [9/10] loss:0.158\n",
      "iteration [9/10] loss:0.326\n",
      "iteration [9/10] loss:0.203\n",
      "iteration [9/10] loss:0.085\n",
      "iteration [9/10] loss:0.206\n",
      "iteration [9/10] loss:0.191\n",
      "iteration [9/10] loss:0.142\n",
      "iteration [9/10] loss:0.232\n",
      "iteration [9/10] loss:0.124\n",
      "iteration [9/10] loss:0.261\n",
      "iteration [9/10] loss:0.476\n",
      "iteration [9/10] loss:0.197\n",
      "iteration [9/10] loss:0.123\n",
      "iteration [9/10] loss:0.153\n",
      "iteration [9/10] loss:0.075\n",
      "iteration [9/10] loss:0.391\n",
      "iteration [9/10] loss:0.246\n",
      "iteration [9/10] loss:0.152\n",
      "iteration [9/10] loss:0.130\n",
      "iteration [9/10] loss:0.305\n",
      "iteration [9/10] loss:0.117\n"
     ]
    }
   ],
   "source": [
    "train_process(model,optimizer=optimizer,epoches=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_process(model):\n",
    "    model.eval()\n",
    "    loss, num = 0, 0\n",
    "    for i, data in enumerate(test_loader):\n",
    "        x, y = data\n",
    "        x, y = Variable(x).cuda(), Variable(y).cuda()\n",
    "        \n",
    "        scores = model(x)\n",
    "        _,pre = scores.max(1)\n",
    "        \n",
    "        loss += (pre==y).sum()\n",
    "        num += scores.size()[0]\n",
    "        \n",
    "        acc = float(loss)/num\n",
    "        print(\"[%d / %d] correct (%.2f)\"%(loss,num,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58 / 64] correct (0.91)\n",
      "[114 / 128] correct (0.89)\n",
      "[169 / 192] correct (0.88)\n",
      "[223 / 256] correct (0.87)\n",
      "[277 / 320] correct (0.87)\n",
      "[330 / 384] correct (0.86)\n",
      "[385 / 448] correct (0.86)\n",
      "[444 / 512] correct (0.87)\n",
      "[501 / 576] correct (0.87)\n",
      "[562 / 640] correct (0.88)\n",
      "[615 / 704] correct (0.87)\n",
      "[670 / 768] correct (0.87)\n",
      "[720 / 832] correct (0.87)\n",
      "[776 / 896] correct (0.87)\n",
      "[827 / 960] correct (0.86)\n",
      "[885 / 1024] correct (0.86)\n",
      "[942 / 1088] correct (0.87)\n",
      "[995 / 1152] correct (0.86)\n",
      "[1051 / 1216] correct (0.86)\n",
      "[1107 / 1280] correct (0.86)\n",
      "[1164 / 1344] correct (0.87)\n",
      "[1224 / 1408] correct (0.87)\n",
      "[1281 / 1472] correct (0.87)\n",
      "[1336 / 1536] correct (0.87)\n",
      "[1392 / 1600] correct (0.87)\n",
      "[1446 / 1664] correct (0.87)\n",
      "[1499 / 1728] correct (0.87)\n",
      "[1550 / 1792] correct (0.86)\n",
      "[1605 / 1856] correct (0.86)\n",
      "[1659 / 1920] correct (0.86)\n",
      "[1710 / 1984] correct (0.86)\n",
      "[1762 / 2048] correct (0.86)\n",
      "[1814 / 2112] correct (0.86)\n",
      "[1868 / 2176] correct (0.86)\n",
      "[1919 / 2240] correct (0.86)\n",
      "[1972 / 2304] correct (0.86)\n",
      "[2025 / 2368] correct (0.86)\n",
      "[2082 / 2432] correct (0.86)\n",
      "[2136 / 2496] correct (0.86)\n",
      "[2186 / 2560] correct (0.85)\n",
      "[2239 / 2624] correct (0.85)\n",
      "[2293 / 2688] correct (0.85)\n",
      "[2352 / 2752] correct (0.85)\n",
      "[2407 / 2816] correct (0.85)\n",
      "[2462 / 2880] correct (0.85)\n",
      "[2517 / 2944] correct (0.85)\n",
      "[2571 / 3008] correct (0.85)\n",
      "[2625 / 3072] correct (0.85)\n",
      "[2680 / 3136] correct (0.85)\n",
      "[2734 / 3200] correct (0.85)\n",
      "[2792 / 3264] correct (0.86)\n",
      "[2851 / 3328] correct (0.86)\n",
      "[2904 / 3392] correct (0.86)\n",
      "[2957 / 3456] correct (0.86)\n",
      "[3012 / 3520] correct (0.86)\n",
      "[3070 / 3584] correct (0.86)\n",
      "[3119 / 3648] correct (0.85)\n",
      "[3178 / 3712] correct (0.86)\n",
      "[3234 / 3776] correct (0.86)\n",
      "[3288 / 3840] correct (0.86)\n",
      "[3345 / 3904] correct (0.86)\n",
      "[3401 / 3968] correct (0.86)\n",
      "[3455 / 4032] correct (0.86)\n",
      "[3509 / 4096] correct (0.86)\n",
      "[3567 / 4160] correct (0.86)\n",
      "[3625 / 4224] correct (0.86)\n",
      "[3683 / 4288] correct (0.86)\n",
      "[3740 / 4352] correct (0.86)\n",
      "[3797 / 4416] correct (0.86)\n",
      "[3854 / 4480] correct (0.86)\n",
      "[3911 / 4544] correct (0.86)\n",
      "[3966 / 4608] correct (0.86)\n",
      "[4021 / 4672] correct (0.86)\n",
      "[4078 / 4736] correct (0.86)\n",
      "[4132 / 4800] correct (0.86)\n",
      "[4192 / 4864] correct (0.86)\n",
      "[4249 / 4928] correct (0.86)\n",
      "[4301 / 4992] correct (0.86)\n",
      "[4355 / 5056] correct (0.86)\n",
      "[4411 / 5120] correct (0.86)\n",
      "[4465 / 5184] correct (0.86)\n",
      "[4516 / 5248] correct (0.86)\n",
      "[4573 / 5312] correct (0.86)\n",
      "[4631 / 5376] correct (0.86)\n",
      "[4686 / 5440] correct (0.86)\n",
      "[4740 / 5504] correct (0.86)\n",
      "[4795 / 5568] correct (0.86)\n",
      "[4854 / 5632] correct (0.86)\n",
      "[4908 / 5696] correct (0.86)\n",
      "[4966 / 5760] correct (0.86)\n",
      "[5026 / 5824] correct (0.86)\n",
      "[5078 / 5888] correct (0.86)\n",
      "[5127 / 5952] correct (0.86)\n",
      "[5183 / 6016] correct (0.86)\n",
      "[5236 / 6080] correct (0.86)\n",
      "[5292 / 6144] correct (0.86)\n",
      "[5345 / 6208] correct (0.86)\n",
      "[5400 / 6272] correct (0.86)\n",
      "[5462 / 6336] correct (0.86)\n",
      "[5516 / 6400] correct (0.86)\n",
      "[5567 / 6464] correct (0.86)\n",
      "[5624 / 6528] correct (0.86)\n",
      "[5682 / 6592] correct (0.86)\n",
      "[5737 / 6656] correct (0.86)\n",
      "[5793 / 6720] correct (0.86)\n",
      "[5844 / 6784] correct (0.86)\n",
      "[5898 / 6848] correct (0.86)\n",
      "[5949 / 6912] correct (0.86)\n",
      "[6004 / 6976] correct (0.86)\n",
      "[6057 / 7040] correct (0.86)\n",
      "[6112 / 7104] correct (0.86)\n",
      "[6166 / 7168] correct (0.86)\n",
      "[6218 / 7232] correct (0.86)\n",
      "[6278 / 7296] correct (0.86)\n",
      "[6337 / 7360] correct (0.86)\n",
      "[6391 / 7424] correct (0.86)\n",
      "[6447 / 7488] correct (0.86)\n",
      "[6498 / 7552] correct (0.86)\n",
      "[6550 / 7616] correct (0.86)\n",
      "[6605 / 7680] correct (0.86)\n",
      "[6666 / 7744] correct (0.86)\n",
      "[6721 / 7808] correct (0.86)\n",
      "[6777 / 7872] correct (0.86)\n",
      "[6831 / 7936] correct (0.86)\n",
      "[6887 / 8000] correct (0.86)\n",
      "[6944 / 8064] correct (0.86)\n",
      "[7003 / 8128] correct (0.86)\n",
      "[7059 / 8192] correct (0.86)\n",
      "[7113 / 8256] correct (0.86)\n",
      "[7167 / 8320] correct (0.86)\n",
      "[7224 / 8384] correct (0.86)\n",
      "[7279 / 8448] correct (0.86)\n",
      "[7332 / 8512] correct (0.86)\n",
      "[7384 / 8576] correct (0.86)\n",
      "[7433 / 8640] correct (0.86)\n",
      "[7492 / 8704] correct (0.86)\n",
      "[7548 / 8768] correct (0.86)\n",
      "[7606 / 8832] correct (0.86)\n",
      "[7666 / 8896] correct (0.86)\n",
      "[7719 / 8960] correct (0.86)\n",
      "[7774 / 9024] correct (0.86)\n",
      "[7828 / 9088] correct (0.86)\n",
      "[7882 / 9152] correct (0.86)\n",
      "[7943 / 9216] correct (0.86)\n",
      "[7994 / 9280] correct (0.86)\n",
      "[8048 / 9344] correct (0.86)\n",
      "[8103 / 9408] correct (0.86)\n",
      "[8155 / 9472] correct (0.86)\n",
      "[8211 / 9536] correct (0.86)\n",
      "[8268 / 9600] correct (0.86)\n",
      "[8325 / 9664] correct (0.86)\n",
      "[8384 / 9728] correct (0.86)\n",
      "[8435 / 9792] correct (0.86)\n",
      "[8485 / 9856] correct (0.86)\n",
      "[8540 / 9920] correct (0.86)\n",
      "[8599 / 9984] correct (0.86)\n",
      "[8612 / 10000] correct (0.86)\n"
     ]
    }
   ],
   "source": [
    "test_process(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:face]",
   "language": "python",
   "name": "conda-env-face-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
